

# main.py
import streamlit as st
import pandas as pd
import numpy as np
import logging
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
import sqlite3
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')
from langchain.prompts import ChatPromptTemplate
import os
# LangChain imports
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import BaseMessage
from langchain.tools import BaseTool
from langchain.agents import AgentType
from langchain.callbacks import StreamlitCallbackHandler
from langchain.memory.chat_memory import BaseChatMemory
from typing import List, Any, Dict,Optional
from langchain_openai import AzureChatOpenAI
import json
from dotenv import load_dotenv
from langchain.chains import LLMChain
load_dotenv() # Carrega variÃ¡veis de ambiente do arquivo .env
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Especialista em AnÃ¡lise de Dados",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

class DataAnalysisMemory:
    """MemÃ³ria personalizada para armazenar anÃ¡lises e conclusÃµes"""
    
    def __init__(self):
        self.analyses = []
        self.conclusions = []
        self.dataset_info = {}
    
    def add_analysis(self, analysis_type: str, result: Any, visualization: str = None):
        """Adiciona uma anÃ¡lise Ã  memÃ³ria"""
        analysis = {
            "type": analysis_type,
            "result": result,
            "visualization": visualization,
            "timestamp": pd.Timestamp.now()
        }
        self.analyses.append(analysis)
    
    def add_conclusion(self, conclusion: str):
        """Adiciona uma conclusÃ£o Ã  memÃ³ria"""
        self.conclusions.append({
            "conclusion": conclusion,
            "timestamp": pd.Timestamp.now()
        })
    
    def get_memory_summary(self) -> str:
        """Retorna um resumo da memÃ³ria para o agente"""
        summary = f"Dataset Info: {self.dataset_info}\n"
        summary += f"Total de anÃ¡lises realizadas: {len(self.analyses)}\n"
        summary += "AnÃ¡lises recentes:\n"
        for analysis in self.analyses[-5:]:
            summary += f"- {analysis['type']}: {str(analysis['result'])[:100]}...\n"
        summary += "ConclusÃµes:\n"
        for conclusion in self.conclusions:
            summary += f"- {conclusion['conclusion']}\n"
        return summary    
    def __init__(self):
        super().__init__()
        self.analyses = []
        self.conclusions = []
        self.dataset_info = {}
    
    def add_analysis(self, analysis_type: str, result: Any, visualization: str = None):
        """Adiciona uma anÃ¡lise Ã  memÃ³ria"""
        analysis = {
            "type": analysis_type,
            "result": result,
            "visualization": visualization,
            "timestamp": pd.Timestamp.now()
        }
        self.analyses.append(analysis)
    
    def add_conclusion(self, conclusion: str):
        """Adiciona uma conclusÃ£o Ã  memÃ³ria"""
        self.conclusions.append({
            "conclusion": conclusion,
            "timestamp": pd.Timestamp.now()
        })
    
    def get_memory_summary(self) -> str:
        """Retorna um resumo da memÃ³ria para o agente"""
        summary = f"Dataset Info: {self.dataset_info}\n"
        summary += f"Total de anÃ¡lises realizadas: {len(self.analyses)}\n"
        summary += "AnÃ¡lises recentes:\n"
        for analysis in self.analyses[-5:]:
            summary += f"- {analysis['type']}: {str(analysis['result'])[:100]}...\n"
        summary += "ConclusÃµes:\n"
        for conclusion in self.conclusions:
            summary += f"- {conclusion['conclusion']}\n"
        return summary

class DataAnalysisTool(BaseTool):
    """Ferramenta customizada para anÃ¡lise de dados"""
    
    name: str = "data_analysis_tool"
    description: str = "Ferramenta para realizar anÃ¡lises exploratÃ³rias de dados"
    df: Optional[pd.DataFrame] = None
    memory: Optional[object] = None
   
    def _run(self, analysis_type: str) -> str:
        """Executa diferentes tipos de anÃ¡lise"""
        try:
            if analysis_type == "basic_info":
                return self._basic_info()
            elif analysis_type == "correlation_analysis":
                return self._correlation_analysis()
            elif analysis_type == "outlier_detection":
                return self._outlier_detection()
            elif analysis_type == "clustering":
                return self._clustering_analysis()
            else:
                return "Tipo de anÃ¡lise nÃ£o reconhecido"
        except Exception as e:
            return f"Erro na anÃ¡lise: {str(e)}"
    
    def _basic_info(self) -> str:
        """InformaÃ§Ãµes bÃ¡sicas do dataset"""
        info = {
            "shape": self.df.shape,
            "columns": list(self.df.columns),
            "dtypes": self.df.dtypes.to_dict(),
            "missing_values": self.df.isnull().sum().to_dict(),
            "numeric_columns": list(self.df.select_dtypes(include=[np.number]).columns),
            "categorical_columns": list(self.df.select_dtypes(include=['object']).columns)
        }
        
        self.memory.dataset_info = info
        self.memory.add_analysis("basic_info", info)
        
        return f"""
        Dataset possui {info['shape'][0]} linhas e {info['shape'][1]} colunas.
        Colunas numÃ©ricas: {info['numeric_columns']}
        Colunas categÃ³ricas: {info['categorical_columns']}
        Valores ausentes: {info['missing_values']}
        """
    
    def _correlation_analysis(self) -> str:
        """AnÃ¡lise de correlaÃ§Ã£o"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            return "NÃ£o hÃ¡ colunas numÃ©ricas para anÃ¡lise de correlaÃ§Ã£o"
        
        correlation_matrix = numeric_df.corr()
        strong_correlations = []
        
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    strong_correlations.append({
                        'var1': correlation_matrix.columns[i],
                        'var2': correlation_matrix.columns[j],
                        'correlation': corr_value
                    })
        
        self.memory.add_analysis("correlation", strong_correlations)
        
        result = "CorrelaÃ§Ãµes fortes encontradas:\n"
        for corr in strong_correlations:
            result += f"- {corr['var1']} vs {corr['var2']}: {corr['correlation']:.3f}\n"
        
        return result if strong_correlations else "Nenhuma correlaÃ§Ã£o forte encontrada (|r| > 0.7)"
    
    def _outlier_detection(self) -> str:
        """DetecÃ§Ã£o de outliers usando IQR"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        outliers_info = {}
        
        for col in numeric_df.columns:
            Q1 = numeric_df[col].quantile(0.25)
            Q3 = numeric_df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]
            outliers_info[col] = {
                'count': len(outliers),
                'percentage': (len(outliers) / len(numeric_df)) * 100,
                'bounds': (lower_bound, upper_bound)
            }
        
        self.memory.add_analysis("outliers", outliers_info)
        
        result = "Outliers detectados:\n"
        for col, info in outliers_info.items():
            if info['count'] > 0:
                result += f"- {col}: {info['count']} outliers ({info['percentage']:.2f}%)\n"
        
        return result
    
    def _clustering_analysis(self) -> str:
        """AnÃ¡lise de clustering"""
        numeric_df = self.df.select_dtypes(include=[np.number]).dropna()
        
        if len(numeric_df.columns) < 2:
            return "Insuficientes colunas numÃ©ricas para clustering"
        
        # Normalizar dados
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(numeric_df)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=3, random_state=42)
        clusters = kmeans.fit_predict(scaled_data)
        
        cluster_info = {
            'n_clusters': 3,
            'cluster_sizes': pd.Series(clusters).value_counts().to_dict(),
            'inertia': kmeans.inertia_
        }
        
        self.memory.add_analysis("clustering", cluster_info)
        
        return f"""
        Clustering K-means com 3 clusters:
        Tamanhos dos clusters: {cluster_info['cluster_sizes']}
        InÃ©rcia: {cluster_info['inertia']:.2f}
        """

class DataAnalysisAgent:
    """Agente especialista em anÃ¡lise de dados"""
    
    def __init__(self, df: pd.DataFrame, db_path: str = "temp_data.db"):
        self.df = df
        self.db_path = db_path
        self.memory = DataAnalysisMemory()
        self.db = None
        self.llm = None
        self.agent_executor = None
        self.chain = None
        self.prompt = None

        self.setup_database()
        self.setup_agent()
    
    def setup_database(self):
        """Configura o banco de dados SQLite"""
        conn = sqlite3.connect(self.db_path)
        self.df.to_sql('data_table', conn, if_exists='replace', index=False)
        conn.close()
        
        self.db = SQLDatabase.from_uri(f"sqlite:///{self.db_path}")
    
    def setup_agent(self):
        """Configura o agente LangChain"""
        # Tente criar o LLM (Azure). Se falhar, llm ficarÃ¡ None.
        try:
            self.llm = AzureChatOpenAI(
                deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
                model="gpt-4o",   # ou "gpt-35-turbo"
                temperature=0,
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            )
            logger.info("AzureChatOpenAI inicializado com sucesso.")
        except Exception as e:
            logger.exception("NÃ£o foi possÃ­vel inicializar AzureChatOpenAI: %s", e)
            self.llm = None

        # Se LLM inicializou, cria toolkit e agent_executor
        if self.llm:
            toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)
            try:
                self.agent_executor = create_sql_agent(
                    llm=self.llm,
                    toolkit=toolkit,
                    verbose=True,
                    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                    memory=ConversationBufferWindowMemory(k=10)
                )
                logger.info("Agent executor criado com sucesso.")
            except Exception as e:
                logger.exception("Erro ao criar agent_executor: %s", e)
                self.agent_executor = None

            # Prompt e chain tambÃ©m
            self.prompt = ChatPromptTemplate.from_template(
                """
                VocÃª Ã© um especialista em anÃ¡lise de dados.
                Dataset carregado com {rows} linhas e {cols} colunas.
                Colunas disponÃ­veis: {columns}.
                Pergunta do usuÃ¡rio: {question}
                Responda de forma detalhada, trazendo possÃ­veis anÃ¡lises, estatÃ­sticas e insights.
                """
            )

            try:
                self.chain = LLMChain(llm=self.llm, prompt=self.prompt)
            except Exception as e:
                logger.exception("Erro ao criar LLMChain: %s", e)
                self.chain = None
        else:
            # Modo fallback (sem LLM) â€” mantÃ©m os atributos definidos
            self.agent_executor = None
            self.chain = None
            self.prompt = ChatPromptTemplate.from_template(
                """
                VocÃª Ã© um especialista em anÃ¡lise de dados (modo offline).
                Dataset carregado com {rows} linhas e {cols} colunas.
                Colunas disponÃ­veis: {columns}.
                Pergunta do usuÃ¡rio: {question}
                Responda de forma detalhada, trazendo possÃ­veis anÃ¡lises, estatÃ­sticas e insights.
                """
            )
            logger.warning("LLM nÃ£o inicializado. Agente pronto em modo offline.")
    
    
    def analyze_data(self, question: str) -> str:
        """Analisa dados baseado na pergunta"""
        if self.agent_executor:
            try:
                response = self.agent_executor.run(
                    f"{question}\nMemÃ³ria atual: {self.memory.get_memory_summary()}"
                )
                return response
            except Exception as e:
                return f"Erro no agente: {str(e)}"
        else:
            return self._manual_analysis(question)
    
    def _manual_analysis(self, question: str) -> str:
        """AnÃ¡lise manual quando o agente nÃ£o estÃ¡ disponÃ­vel"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['bÃ¡sica', 'resumo', 'overview', 'informaÃ§Ã£o']):
            return self._get_basic_summary()
        elif any(word in question_lower for word in ['correlaÃ§Ã£o', 'relaÃ§Ã£o', 'correlation']):
            return self._get_correlation_analysis()
        elif any(word in question_lower for word in ['outlier', 'anomalia', 'atÃ­pico']):
            return self._get_outlier_analysis()
        elif any(word in question_lower for word in ['cluster', 'agrupamento', 'padrÃ£o']):
            return self._get_clustering_analysis()
        else:
            return "Pergunta nÃ£o reconhecida. Tente perguntas sobre informaÃ§Ãµes bÃ¡sicas, correlaÃ§Ãµes, outliers ou clustering."
    
    def _get_basic_summary(self) -> str:
        """Retorna resumo bÃ¡sico dos dados"""
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        
        summary = f"""
        ğŸ“Š **RESUMO DO DATASET**
        
        **DimensÃµes:** {self.df.shape[0]} linhas Ã— {self.df.shape[1]} colunas
        
        **Tipos de Dados:**
        - NumÃ©ricas: {list(numeric_cols)} ({len(numeric_cols)} colunas)
        - CategÃ³ricas: {list(categorical_cols)} ({len(categorical_cols)} colunas)
        
        **Valores Ausentes:**
        {self.df.isnull().sum().to_string()}
        
        **EstatÃ­sticas Descritivas (NumÃ©ricas):**
        {self.df[numeric_cols].describe().to_string()}
        """
        
        # Adicionar Ã  memÃ³ria
        self.memory.add_analysis("basic_summary", {
            "shape": self.df.shape,
            "numeric_cols": list(numeric_cols),
            "categorical_cols": list(categorical_cols)
        })
        
        return summary
    
    def _get_correlation_analysis(self) -> str:
        """AnÃ¡lise de correlaÃ§Ã£o"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        
        if numeric_df.empty:
            return "âŒ NÃ£o hÃ¡ colunas numÃ©ricas para anÃ¡lise de correlaÃ§Ã£o."
        
        corr_matrix = numeric_df.corr()
        
        # Encontrar correlaÃ§Ãµes fortes
        strong_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_value = corr_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    strong_corr.append((
                        corr_matrix.columns[i],
                        corr_matrix.columns[j],
                        corr_value
                    ))
        
        result = "ğŸ”— **ANÃLISE DE CORRELAÃ‡ÃƒO**\n\n"
        
        if strong_corr:
            result += "**CorrelaÃ§Ãµes Fortes (|r| > 0.7):**\n"
            for var1, var2, corr in strong_corr:
                strength = "muito forte" if abs(corr) > 0.9 else "forte"
                direction = "positiva" if corr > 0 else "negativa"
                result += f"- {var1} â†” {var2}: {corr:.3f} ({strength}, {direction})\n"
        else:
            result += "Nenhuma correlaÃ§Ã£o forte encontrada (|r| > 0.7)\n"
        
        # Adicionar Ã  memÃ³ria
        self.memory.add_analysis("correlation", strong_corr)
        
        return result
    
    def _get_outlier_analysis(self) -> str:
        """AnÃ¡lise de outliers"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        
        if numeric_df.empty:
            return "âŒ NÃ£o hÃ¡ colunas numÃ©ricas para anÃ¡lise de outliers."
        
        outliers_summary = {}
        
        for col in numeric_df.columns:
            Q1 = numeric_df[col].quantile(0.25)
            Q3 = numeric_df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]
            outliers_summary[col] = {
                'count': len(outliers),
                'percentage': (len(outliers) / len(numeric_df)) * 100,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound
            }
        
        result = "ğŸš¨ **ANÃLISE DE OUTLIERS (MÃ©todo IQR)**\n\n"
        
        for col, info in outliers_summary.items():
            if info['count'] > 0:
                result += f"**{col}:**\n"
                result += f"  - Outliers detectados: {info['count']} ({info['percentage']:.2f}% dos dados)\n"
                result += f"  - Limites: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\n\n"
        
        # Adicionar Ã  memÃ³ria
        self.memory.add_analysis("outliers", outliers_summary)
        
        return result
    
    def _get_clustering_analysis(self) -> str:
        """AnÃ¡lise de clustering"""
        numeric_df = self.df.select_dtypes(include=[np.number]).dropna()
        
        if len(numeric_df.columns) < 2:
            return "âŒ Insuficientes colunas numÃ©ricas para anÃ¡lise de clustering."
        
        # Padronizar dados
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(numeric_df)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=3, random_state=42)
        clusters = kmeans.fit_predict(scaled_data)
        
        cluster_sizes = pd.Series(clusters).value_counts().sort_index()
        
        result = "ğŸ” **ANÃLISE DE CLUSTERING (K-means, k=3)**\n\n"
        result += f"**DistribuiÃ§Ã£o dos Clusters:**\n"
        for cluster_id, size in cluster_sizes.items():
            percentage = (size / len(clusters)) * 100
            result += f"  - Cluster {cluster_id}: {size} pontos ({percentage:.1f}%)\n"
        
        result += f"\n**InÃ©rcia:** {kmeans.inertia_:.2f}"
        result += f"\n**Centros dos Clusters:** {len(kmeans.cluster_centers_)} centros identificados"
        
        # Adicionar Ã  memÃ³ria
        self.memory.add_analysis("clustering", {
            'cluster_sizes': cluster_sizes.to_dict(),
            'inertia': kmeans.inertia_
        })
        
        return result
    
    def get_conclusions(self) -> str:
        """Gera conclusÃµes baseadas nas anÃ¡lises realizadas"""
        if not self.memory.analyses:
            return "Nenhuma anÃ¡lise foi realizada ainda."
        
        conclusions = []
        
        # AnÃ¡lise do dataset
        if self.memory.dataset_info:
            info = self.memory.dataset_info
            if info.get('missing_values'):
                missing_count = sum([v for v in info['missing_values'].values() if v > 0])
                if missing_count > 0:
                    conclusions.append(f"O dataset possui {missing_count} valores ausentes que podem precisar de tratamento.")
        
        # ConclusÃµes sobre correlaÃ§Ãµes
        for analysis in self.memory.analyses:
            if analysis['type'] == 'correlation' and analysis['result']:
                conclusions.append("Foram identificadas correlaÃ§Ãµes fortes entre variÃ¡veis, indicando possÃ­veis relaÃ§Ãµes lineares.")
        
        # ConclusÃµes sobre outliers
        outlier_analyses = [a for a in self.memory.analyses if a['type'] == 'outliers']
        if outlier_analyses:
            latest_outliers = outlier_analyses[-1]['result']
            total_outliers = sum([info['count'] for info in latest_outliers.values()])
            if total_outliers > 0:
                conclusions.append(f"Foram detectados {total_outliers} outliers no dataset que podem afetar as anÃ¡lises.")
        
        # ConclusÃµes sobre clustering
        cluster_analyses = [a for a in self.memory.analyses if a['type'] == 'clustering']
        if cluster_analyses:
            conclusions.append("Os dados mostram padrÃµes de agrupamento, sugerindo diferentes segmentos nos dados.")
        
        # Adicionar conclusÃµes Ã  memÃ³ria
        final_conclusion = "\n".join([f"â€¢ {c}" for c in conclusions])
        if final_conclusion:
            self.memory.add_conclusion(final_conclusion)
        
        return final_conclusion if conclusions else "Com base nas anÃ¡lises realizadas, nÃ£o foram identificados padrÃµes significativos que requerem atenÃ§Ã£o especial."

def create_visualizations(df: pd.DataFrame, analysis_type: str):
    """Cria visualizaÃ§Ãµes baseadas no tipo de anÃ¡lise"""
    
    if analysis_type == "distribution":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            fig = go.Figure()
            
            for col in numeric_cols[:4]:  # MÃ¡ximo 4 colunas
                fig.add_trace(go.Histogram(
                    x=df[col],
                    name=col,
                    opacity=0.7
                ))
            
            fig.update_layout(
                title="DistribuiÃ§Ã£o das VariÃ¡veis NumÃ©ricas",
                xaxis_title="Valor",
                yaxis_title="FrequÃªncia",
                barmode='overlay'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "correlation":
        numeric_df = df.select_dtypes(include=[np.number])
        
        if not numeric_df.empty and len(numeric_df.columns) > 1:
            corr_matrix = numeric_df.corr()
            
            fig = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                title="Matrix de CorrelaÃ§Ã£o",
                color_continuous_scale='RdBu_r'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "outliers":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            fig = go.Figure()
            
            for col in numeric_cols[:4]:  # MÃ¡ximo 4 colunas
                fig.add_trace(go.Box(
                    y=df[col],
                    name=col
                ))
            
            fig.update_layout(
                title="DetecÃ§Ã£o de Outliers (Box Plots)",
                yaxis_title="Valor"
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "scatter":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) >= 2:
            col1, col2 = numeric_cols[0], numeric_cols[1]
            
            fig = px.scatter(
                df,
                x=col1,
                y=col2,
                title=f"GrÃ¡fico de DispersÃ£o: {col1} vs {col2}"
            )
            
            st.plotly_chart(fig, use_container_width=True)

def main():
    """FunÃ§Ã£o principal do aplicativo"""
    
    # TÃ­tulo e descriÃ§Ã£o
    st.title("ğŸ” Especialista em AnÃ¡lise de Dados com IA")
    st.markdown("### Sistema inteligente para anÃ¡lise exploratÃ³ria de dados com agentes LangChain")
    
    

    # Sidebar para upload e configuraÃ§Ãµes
    with st.sidebar:
        st.header("ğŸ“ Upload de Dados")
        
        uploaded_file = st.file_uploader(
            "FaÃ§a upload do seu arquivo",
            type=['xls', 'xlsx', 'csv', 'txt'],
            help="Upload de um arquivo para anÃ¡lise"
        )
        
        if uploaded_file is not None:
            try:
                # Carregar dados
                df = pd.read_csv(uploaded_file)
                st.success(f"Arquivo carregado: {uploaded_file.name}")
                st.info(f"DimensÃµes: {df.shape[0]} linhas Ã— {df.shape[1]} colunas")
                
                # Armazenar no session state
                st.session_state['df'] = df
                st.session_state['uploaded'] = True
                
            except Exception as e:
                st.error(f"Erro ao carregar arquivo: {str(e)}")
                st.session_state['uploaded'] = False
        
        #Caixa de texto para perguntas
        st.header("â“ Diga sua pergunta")
        text_area = st.text_area(
            "Digite sua pergunta sobre os dados apÃ³s o upload",
            placeholder="Exemplo:\n- Quais sÃ£o as principais correlaÃ§Ãµes nos dados?",
            height=130,
            help="Seja especÃ­fico em sua pergunta para obter melhores respostas"
        )
        if st.button("ğŸš€ Enviar Pergunta"):
            if text_area.strip():
                with st.spinner("Processando..."):
                    try:
                        response = st.session_state.agent.analyze_data(text_area)
                        st.success("âœ… Resposta do Agente:")
                        st.write(response)
                    except Exception as e:
                        st.error(f"âŒ Erro: {str(e)}")
            else:
                st.warning("âš ï¸ Digite uma pergunta antes de enviar.")    
    
    # Ãrea principal
    if st.session_state.get('uploaded', False) and 'df' in st.session_state:
        df = st.session_state['df']
        
        # Inicializar agente
        if 'agent' not in st.session_state:
            db_path = "temp_data.db"
            st.session_state['agent'] = DataAnalysisAgent(df, db_path)
        
        agent = st.session_state['agent']
        
        # Tabs principais
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“Š VisÃ£o Geral", 
            "ğŸ¤– Chat com IA", 
            "ğŸ“ˆ VisualizaÃ§Ãµes", 
            "ğŸ’¡ ConclusÃµes"
        ])
        
        with tab1:
            st.header("VisÃ£o Geral dos Dados")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("InformaÃ§Ãµes BÃ¡sicas")
                st.write(f"**Linhas:** {df.shape[0]}")
                st.write(f"**Colunas:** {df.shape[1]}")
                st.write(f"**MemÃ³ria:** {df.memory_usage().sum() / 1024**2:.2f} MB")
            
            with col2:
                st.subheader("Tipos de Dados")
                dtype_counts = df.dtypes.value_counts()
                st.write(dtype_counts)
            
            st.subheader("PrÃ©via dos Dados")
            st.dataframe(df.head(10))
            
            st.subheader("InformaÃ§Ãµes Detalhadas")
            st.text(df.info())
            
            st.subheader("EstatÃ­sticas Descritivas")
            st.dataframe(df.describe())
        
        with tab2:
            st.header("ğŸ’¬ Chat com o Especialista em Dados")
            
            # Perguntas sugeridas
            st.subheader("Perguntas Sugeridas:")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ“‹ Resumo bÃ¡sico dos dados"):
                    with st.spinner("Analisando..."):
                        response = agent.analyze_data("ForneÃ§a um resumo bÃ¡sico dos dados")
                        st.write(response)
                
                if st.button("ğŸ”— AnÃ¡lise de correlaÃ§Ãµes"):
                    with st.spinner("Calculando correlaÃ§Ãµes..."):
                        response = agent.analyze_data("Analise as correlaÃ§Ãµes entre as variÃ¡veis")
                        st.write(response)
            
            with col2:
                if st.button("ğŸš¨ Detectar outliers"):
                    with st.spinner("Detectando anomalias..."):
                        response = agent.analyze_data("Detecte outliers nos dados")
                        st.write(response)
                
                if st.button("ğŸ” AnÃ¡lise de clustering"):
                    with st.spinner("Analisando padrÃµes..."):
                        response = agent.analyze_data("Realize anÃ¡lise de clustering")
                        st.write(response)
            
            st.divider()
            
            # Chat personalizado
            st.subheader("ğŸ’¬ FaÃ§a sua pergunta ao especialista:")
            
            # Container para o histÃ³rico de chat
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
            
            # Exibir histÃ³rico de chat
            if st.session_state.chat_history:
                st.subheader("ğŸ“‹ HistÃ³rico da Conversa:")
                for i, (q, a) in enumerate(st.session_state.chat_history):
                    with st.expander(f"Pergunta {i+1}: {q[:50]}..."):
                        st.write(f"**ğŸ¤” Pergunta:** {q}")
                        st.write(f"**ğŸ¤– Resposta:** {a}")
                
                # BotÃ£o para limpar histÃ³rico
                if st.button("ğŸ—‘ï¸ Limpar HistÃ³rico"):
                    st.session_state.chat_history = []
                    st.rerun()
            
            st.divider()
            
            # Ãrea de entrada de texto
            with st.form("chat_form"):
                question = st.text_area(
                    "Digite sua pergunta sobre os dados:",
                    placeholder="Exemplo:\n- Quais sÃ£o as principais correlaÃ§Ãµes nos dados?\n- Existem outliers que devo me preocupar?\n- Como estÃ£o distribuÃ­das as variÃ¡veis?\n- Que padrÃµes vocÃª identifica nos dados?",
                    height=100,
                    help="Seja especÃ­fico em sua pergunta para obter melhores respostas"
                )
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    submit_button = st.form_submit_button("ğŸš€ Enviar Pergunta", use_container_width=True)
                with col2:
                    clear_button = st.form_submit_button("ğŸ§¹ Limpar", use_container_width=True)
            
            # Processamento da pergunta
            if submit_button and question.strip():
                with st.spinner("ğŸ” Analisando seus dados e processando a pergunta..."):
                    try:
                        # Adicionar contexto sobre os dados Ã  pergunta
                        enhanced_question = f"""
                        Baseado no dataset carregado com as seguintes caracterÃ­sticas:
                        - Formato: {df.shape[0]} linhas e {df.shape[1]} colunas
                        - Colunas numÃ©ricas: {list(df.select_dtypes(include=[np.number]).columns)}
                        - Colunas categÃ³ricas: {list(df.select_dtypes(include=['object']).columns)}
                        
                        Pergunta do usuÃ¡rio: {question}
                        
                        Por favor, forneÃ§a uma anÃ¡lise detalhada e especÃ­fica baseada nos dados.
                        """
                        
                        response = agent.analyze_data(enhanced_question)
                        
                        # Adicionar ao histÃ³rico
                        st.session_state.chat_history.append((question, response))
                        
                        # Exibir resposta
                        st.success("âœ… AnÃ¡lise concluÃ­da!")
                        
                        # Container para a resposta mais visÃ­vel
                        with st.container():
                            st.markdown("### ğŸ¤– Resposta do Especialista:")
                            
                            # Criar tabs para diferentes visualizaÃ§Ãµes da resposta
                            tab_resp, tab_viz = st.tabs(["ğŸ“ Resposta", "ğŸ“Š VisualizaÃ§Ãµes"])
                            
                            with tab_resp:
                                st.markdown(response)
                                
                                # BotÃµes de aÃ§Ã£o
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    if st.button("ğŸ‘ Ãštil"):
                                        st.success("Obrigado pelo feedback!")
                                with col2:
                                    if st.button("ğŸ”„ Reformular"):
                                        st.info("Tente fazer a pergunta de forma diferente")
                                with col3:
                                    if st.button("ğŸ’¾ Salvar"):
                                        # Aqui vocÃª pode implementar salvamento
                                        st.info("Resposta salva no histÃ³rico!")
                            
                            with tab_viz:
                                # Sugerir visualizaÃ§Ãµes baseadas na pergunta
                                question_lower = question.lower()
                                if any(word in question_lower for word in ['correlaÃ§Ã£o', 'relaÃ§Ã£o', 'correlation']):
                                    st.info("ğŸ’¡ VisualizaÃ§Ã£o sugerida: VÃ¡ para a aba 'VisualizaÃ§Ãµes' e selecione 'CorrelaÃ§Ãµes'")
                                elif any(word in question_lower for word in ['outlier', 'anomalia', 'atÃ­pico']):
                                    st.info("ğŸ’¡ VisualizaÃ§Ã£o sugerida: VÃ¡ para a aba 'VisualizaÃ§Ãµes' e selecione 'Outliers'")
                                elif any(word in question_lower for word in ['distribuiÃ§Ã£o', 'histograma']):
                                    st.info("ğŸ’¡ VisualizaÃ§Ã£o sugerida: VÃ¡ para a aba 'VisualizaÃ§Ãµes' e selecione 'DistribuiÃ§Ãµes'")
                                else:
                                    st.info("ğŸ’¡ Explore a aba 'VisualizaÃ§Ãµes' para grÃ¡ficos relacionados Ã  sua pergunta")
                    
                    except Exception as e:
                        st.error(f"âŒ Erro ao processar a pergunta: {str(e)}")
                        st.info("ğŸ’¡ Tente reformular sua pergunta ou use uma das perguntas sugeridas")
            
            elif submit_button and not question.strip():
                st.warning("âš ï¸ Por favor, digite uma pergunta antes de enviar.")
            
            elif clear_button:
                st.info("âœ… Campo de pergunta limpo!")
            
            # SeÃ§Ã£o de dicas
            with st.expander("ğŸ’¡ Dicas para fazer boas perguntas"):
                st.markdown("""
                **ğŸ¯ Para obter melhores respostas:**
                
                **âœ… Perguntas especÃ­ficas funcionam melhor:**
                - "Qual a correlaÃ§Ã£o entre idade e salÃ¡rio?"
                - "Quantos outliers existem na coluna de vendas?"
                - "Quais variÃ¡veis tÃªm maior impacto no resultado?"
                
                **âŒ Evite perguntas muito genÃ©ricas:**
                - "Me fale sobre os dados"
                - "O que vocÃª acha?"
                - "AnÃ¡lise tudo"
                
                **ğŸ” Tipos de anÃ¡lise disponÃ­veis:**
                - **Descritiva:** estatÃ­sticas, distribuiÃ§Ãµes, resumos
                - **CorrelaÃ§Ã£o:** relacionamentos entre variÃ¡veis
                - **Outliers:** valores atÃ­picos e anomalias
                - **Clustering:** padrÃµes e agrupamentos
                - **TendÃªncias:** anÃ¡lise temporal e padrÃµes
                
                **ğŸ’¬ Exemplos de perguntas por categoria:**
                
                **ğŸ“Š AnÃ¡lise Descritiva:**
                - "Quais sÃ£o as estatÃ­sticas bÃ¡sicas de cada variÃ¡vel?"
                - "Como estÃ£o distribuÃ­dos os dados?"
                - "HÃ¡ muitos valores ausentes?"
                
                **ğŸ”— AnÃ¡lise de Relacionamentos:**
                - "Existe correlaÃ§Ã£o entre X e Y?"
                - "Quais variÃ¡veis se relacionam mais fortemente?"
                - "Como X influencia Y?"
                
                **ğŸš¨ DetecÃ§Ã£o de Anomalias:**
                - "HÃ¡ outliers nos dados?"
                - "Quais valores sÃ£o considerados atÃ­picos?"
                - "Os outliers afetam a anÃ¡lise?"
                
                **ğŸ” IdentificaÃ§Ã£o de PadrÃµes:**
                - "Existem grupos naturais nos dados?"
                - "HÃ¡ padrÃµes temporais?"
                - "Que segmentos posso identificar?"
                """)
            
            # Atalhos para perguntas comuns
            st.subheader("âš¡ AnÃ¡lises RÃ¡pidas:")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“ˆ AnÃ¡lise Completa", help="AnÃ¡lise exploratÃ³ria completa dos dados"):
                    quick_question = "FaÃ§a uma anÃ¡lise exploratÃ³ria completa dos dados, incluindo estatÃ­sticas descritivas, correlaÃ§Ãµes, outliers e padrÃµes identificados."
                    with st.spinner("Realizando anÃ¡lise completa..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### ğŸ¤– AnÃ¡lise Completa:")
                        st.markdown(response)
            
            with col2:
                if st.button("ğŸ”— CorrelaÃ§Ãµes", help="AnÃ¡lise de correlaÃ§Ãµes entre variÃ¡veis"):
                    quick_question = "Analise as correlaÃ§Ãµes entre todas as variÃ¡veis numÃ©ricas e identifique os relacionamentos mais significativos."
                    with st.spinner("Analisando correlaÃ§Ãµes..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### ğŸ”— AnÃ¡lise de CorrelaÃ§Ãµes:")
                        st.markdown(response)
            
            with col3:
                if st.button("âš ï¸ Problemas", help="Identifica problemas nos dados"):
                    quick_question = "Identifique possÃ­veis problemas nos dados como outliers, valores ausentes, inconsistÃªncias e outros issues que precisam de atenÃ§Ã£o."
                    with st.spinner("Identificando problemas..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### âš ï¸ Problemas Identificados:")
                        st.markdown(response)
        
        with tab3:
            st.header("ğŸ“ˆ VisualizaÃ§Ãµes")
            
            viz_type = st.selectbox(
                "Selecione o tipo de visualizaÃ§Ã£o:",
                ["DistribuiÃ§Ãµes", "CorrelaÃ§Ãµes", "Outliers", "DispersÃ£o"]
            )
            
            if st.button("Gerar VisualizaÃ§Ã£o"):
                with st.spinner("Criando visualizaÃ§Ã£o..."):
                    if viz_type == "DistribuiÃ§Ãµes":
                        create_visualizations(df, "distribution")
                    elif viz_type == "CorrelaÃ§Ãµes":
                        create_visualizations(df, "correlation")
                    elif viz_type == "Outliers":
                        create_visualizations(df, "outliers")
                    elif viz_type == "DispersÃ£o":
                        create_visualizations(df, "scatter")
        
        with tab4:
            st.header("ğŸ’¡ ConclusÃµes e Insights")
            
            if st.button("ğŸ§  Gerar ConclusÃµes"):
                with st.spinner("Analisando todos os dados e gerando insights..."):
                    conclusions = agent.get_conclusions()
                    
                    if conclusions:
                        st.success("ConclusÃµes geradas com base nas anÃ¡lises realizadas:")
                        st.write(conclusions)
                    else:
                        st.info("Realize algumas anÃ¡lises primeiro para gerar conclusÃµes.")
            
            # Mostrar memÃ³ria do agente
            st.subheader("ğŸ“š MemÃ³ria do Agente")
            if agent.memory.analyses:
                st.write(f"**AnÃ¡lises realizadas:** {len(agent.memory.analyses)}")
                st.write(f"**ConclusÃµes armazenadas:** {len(agent.memory.conclusions)}")
                
                with st.expander("Ver detalhes da memÃ³ria"):
                    st.text(agent.memory.get_memory_summary())
            else:
                st.info("Nenhuma anÃ¡lise realizada ainda. Use o chat para fazer perguntas sobre os dados.")
    
    else:
        # PÃ¡gina inicial quando nÃ£o hÃ¡ dados carregados
        st.info("ğŸ‘ˆ FaÃ§a upload de um arquivo CSV na sidebar para comeÃ§ar a anÃ¡lise")
        
        # Tutorial de uso
        st.subheader("ğŸš€ Como usar este sistema:")
        
        st.markdown("""
        1. **Upload de Dados**: Carregue seu arquivo CSV usando a sidebar
        2. **VisÃ£o Geral**: Explore informaÃ§Ãµes bÃ¡sicas sobre seus dados
        3. **Chat com IA**: FaÃ§a perguntas em linguagem natural sobre os dados
        4. **VisualizaÃ§Ãµes**: Gere grÃ¡ficos automÃ¡ticos para diferentes tipos de anÃ¡lise
        5. **ConclusÃµes**: Obtenha insights inteligentes baseados em todas as anÃ¡lises
        
        ### ğŸ¤– Capacidades do Agente:
        - AnÃ¡lise exploratÃ³ria completa (EDA)
        - DetecÃ§Ã£o de padrÃµes e tendÃªncias
        - IdentificaÃ§Ã£o de outliers e anomalias
        - AnÃ¡lise de correlaÃ§Ãµes entre variÃ¡veis
        - Clustering e segmentaÃ§Ã£o
        - ConclusÃµes inteligentes com memÃ³ria persistente
        
        ### ğŸ“Š Tipos de Perguntas que pode fazer:
        - "Quais sÃ£o os principais insights destes dados?"
        - "Existem correlaÃ§Ãµes fortes entre as variÃ¡veis?"
        - "Como estÃ£o distribuÃ­dos os dados?"
        - "HÃ¡ outliers que devo me preocupar?"
        - "Quais padrÃµes vocÃª encontrou?"
        """)
        
        # Exemplo de dataset
        st.subheader("ğŸ“‹ Dataset de Exemplo")
        st.markdown("Experimente com este dataset de exemplo:")
        
        if st.button("Gerar Dataset de Exemplo"):
            # Criar dataset de exemplo
            np.random.seed(42)
            n_samples = 1000
            
            example_data = {
                'idade': np.random.randint(18, 80, n_samples),
                'salario': np.random.exponential(50000, n_samples) + 30000,
                'experiencia': np.random.randint(0, 40, n_samples),
                'satisfacao': np.random.uniform(1, 11, n_samples),
                'departamento': np.random.choice(['TI', 'Vendas', 'Marketing', 'RH', 'Financeiro'], n_samples),
                'performance': np.random.normal(7, 2, n_samples)
            }
            
            # Adicionar algumas correlaÃ§Ãµes
            example_data['salario'] += example_data['experiencia'] * 1000
            example_data['satisfacao'] += (example_data['performance'] - 7) * 0.5
            
            example_df = pd.DataFrame(example_data)
            
            # Salvar arquivo temporÃ¡rio
            example_df.to_csv('exemplo_dataset.csv', index=False)
            
            st.success("Dataset de exemplo criado!")
            st.dataframe(example_df.head())
            
            # Carregar automaticamente
            st.session_state['df'] = example_df
            st.session_state['uploaded'] = True
            st.rerun()

if __name__ == "__main__":
    # Inicializar session state
    if 'uploaded' not in st.session_state:
        st.session_state['uploaded'] = False
    
    main()