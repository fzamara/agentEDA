

# main.py
import streamlit as st
import pandas as pd
import numpy as np
import logging
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
import sqlite3
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')
from langchain.prompts import ChatPromptTemplate
import os
# LangChain imports
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import BaseMessage
from langchain.tools import BaseTool
from langchain.agents import AgentType
from langchain.callbacks import StreamlitCallbackHandler
from langchain.memory.chat_memory import BaseChatMemory
from typing import List, Any, Dict,Optional
from langchain_openai import AzureChatOpenAI
import json
from dotenv import load_dotenv
from langchain.chains import LLMChain
load_dotenv() # Carrega vari√°veis de ambiente do arquivo .env
logger = logging.getLogger(__name__)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Especialista em An√°lise de Dados",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

class DataAnalysisMemory:
    """Mem√≥ria personalizada para armazenar an√°lises e conclus√µes"""
    
    def __init__(self):
        self.analyses = []
        self.conclusions = []
        self.dataset_info = {}
    
    def add_analysis(self, analysis_type: str, result: Any, visualization: str = None):
        """Adiciona uma an√°lise √† mem√≥ria"""
        analysis = {
            "type": analysis_type,
            "result": result,
            "visualization": visualization,
            "timestamp": pd.Timestamp.now()
        }
        self.analyses.append(analysis)
    
    def add_conclusion(self, conclusion: str):
        """Adiciona uma conclus√£o √† mem√≥ria"""
        self.conclusions.append({
            "conclusion": conclusion,
            "timestamp": pd.Timestamp.now()
        })
    
    def get_memory_summary(self) -> str:
        """Retorna um resumo da mem√≥ria para o agente"""
        summary = f"Dataset Info: {self.dataset_info}\n"
        summary += f"Total de an√°lises realizadas: {len(self.analyses)}\n"
        summary += "An√°lises recentes:\n"
        for analysis in self.analyses[-5:]:
            summary += f"- {analysis['type']}: {str(analysis['result'])[:100]}...\n"
        summary += "Conclus√µes:\n"
        for conclusion in self.conclusions:
            summary += f"- {conclusion['conclusion']}\n"
        return summary    
    def __init__(self):
        super().__init__()
        self.analyses = []
        self.conclusions = []
        self.dataset_info = {}
    
    def add_analysis(self, analysis_type: str, result: Any, visualization: str = None):
        """Adiciona uma an√°lise √† mem√≥ria"""
        analysis = {
            "type": analysis_type,
            "result": result,
            "visualization": visualization,
            "timestamp": pd.Timestamp.now()
        }
        self.analyses.append(analysis)
    
    def add_conclusion(self, conclusion: str):
        """Adiciona uma conclus√£o √† mem√≥ria"""
        self.conclusions.append({
            "conclusion": conclusion,
            "timestamp": pd.Timestamp.now()
        })
    
    def get_memory_summary(self) -> str:
        """Retorna um resumo da mem√≥ria para o agente"""
        summary = f"Dataset Info: {self.dataset_info}\n"
        summary += f"Total de an√°lises realizadas: {len(self.analyses)}\n"
        summary += "An√°lises recentes:\n"
        for analysis in self.analyses[-5:]:
            summary += f"- {analysis['type']}: {str(analysis['result'])[:100]}...\n"
        summary += "Conclus√µes:\n"
        for conclusion in self.conclusions:
            summary += f"- {conclusion['conclusion']}\n"
        return summary

class DataAnalysisTool(BaseTool):
    """Ferramenta customizada para an√°lise de dados"""
    
    name: str = "data_analysis_tool"
    description: str = "Ferramenta para realizar an√°lises explorat√≥rias de dados"
    df: Optional[pd.DataFrame] = None
    memory: Optional[object] = None
   
    def _run(self, analysis_type: str) -> str:
        """Executa diferentes tipos de an√°lise"""
        try:
            if analysis_type == "basic_info":
                return self._basic_info()
            elif analysis_type == "correlation_analysis":
                return self._correlation_analysis()
            elif analysis_type == "outlier_detection":
                return self._outlier_detection()
            elif analysis_type == "clustering":
                return self._clustering_analysis()
            else:
                return "Tipo de an√°lise n√£o reconhecido"
        except Exception as e:
            return f"Erro na an√°lise: {str(e)}"
    
    def _basic_info(self) -> str:
        """Informa√ß√µes b√°sicas do dataset"""
        info = {
            "shape": self.df.shape,
            "columns": list(self.df.columns),
            "dtypes": self.df.dtypes.to_dict(),
            "missing_values": self.df.isnull().sum().to_dict(),
            "numeric_columns": list(self.df.select_dtypes(include=[np.number]).columns),
            "categorical_columns": list(self.df.select_dtypes(include=['object']).columns)
        }
        
        self.memory.dataset_info = info
        self.memory.add_analysis("basic_info", info)
        
        return f"""
        Dataset possui {info['shape'][0]} linhas e {info['shape'][1]} colunas.
        Colunas num√©ricas: {info['numeric_columns']}
        Colunas categ√≥ricas: {info['categorical_columns']}
        Valores ausentes: {info['missing_values']}
        """
    
    def _correlation_analysis(self) -> str:
        """An√°lise de correla√ß√£o"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        if numeric_df.empty:
            return "N√£o h√° colunas num√©ricas para an√°lise de correla√ß√£o"
        
        correlation_matrix = numeric_df.corr()
        strong_correlations = []
        
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    strong_correlations.append({
                        'var1': correlation_matrix.columns[i],
                        'var2': correlation_matrix.columns[j],
                        'correlation': corr_value
                    })
        
        self.memory.add_analysis("correlation", strong_correlations)
        
        result = "Correla√ß√µes fortes encontradas:\n"
        for corr in strong_correlations:
            result += f"- {corr['var1']} vs {corr['var2']}: {corr['correlation']:.3f}\n"
        
        return result if strong_correlations else "Nenhuma correla√ß√£o forte encontrada (|r| > 0.7)"
    
    def _outlier_detection(self) -> str:
        """Detec√ß√£o de outliers usando IQR"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        outliers_info = {}
        
        for col in numeric_df.columns:
            Q1 = numeric_df[col].quantile(0.25)
            Q3 = numeric_df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]
            outliers_info[col] = {
                'count': len(outliers),
                'percentage': (len(outliers) / len(numeric_df)) * 100,
                'bounds': (lower_bound, upper_bound)
            }
        
        self.memory.add_analysis("outliers", outliers_info)
        
        result = "Outliers detectados:\n"
        for col, info in outliers_info.items():
            if info['count'] > 0:
                result += f"- {col}: {info['count']} outliers ({info['percentage']:.2f}%)\n"
        
        return result
    
    def _clustering_analysis(self) -> str:
        """An√°lise de clustering"""
        numeric_df = self.df.select_dtypes(include=[np.number]).dropna()
        
        if len(numeric_df.columns) < 2:
            return "Insuficientes colunas num√©ricas para clustering"
        
        # Normalizar dados
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(numeric_df)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=3, random_state=42)
        clusters = kmeans.fit_predict(scaled_data)
        
        cluster_info = {
            'n_clusters': 3,
            'cluster_sizes': pd.Series(clusters).value_counts().to_dict(),
            'inertia': kmeans.inertia_
        }
        
        self.memory.add_analysis("clustering", cluster_info)
        
        return f"""
        Clustering K-means com 3 clusters:
        Tamanhos dos clusters: {cluster_info['cluster_sizes']}
        In√©rcia: {cluster_info['inertia']:.2f}
        """

class DataAnalysisAgent:
    """Agente especialista em an√°lise de dados"""
    
    def __init__(self, df: pd.DataFrame, db_path: str = "temp_data.db"):
        self.df = df
        self.db_path = db_path
        self.memory = DataAnalysisMemory()
        self.db = None
        self.llm = None
        self.agent_executor = None
        self.chain = None
        self.prompt = None

        self.setup_database()
        self.setup_agent()
    
    def setup_database(self):
        """Configura o banco de dados SQLite"""
        conn = sqlite3.connect(self.db_path)
        self.df.to_sql('data_table', conn, if_exists='replace', index=False)
        conn.close()
        
        self.db = SQLDatabase.from_uri(f"sqlite:///{self.db_path}")
    
    def setup_agent(self):
        """Configura o agente LangChain"""
        # Tente criar o LLM (Azure). Se falhar, llm ficar√° None.
        try:
            self.llm = AzureChatOpenAI(
                deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
                model="gpt-4o",   # ou "gpt-35-turbo"
                temperature=0,
                api_key=os.getenv("AZURE_OPENAI_API_KEY"),
                azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
                api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            )
            logger.info("AzureChatOpenAI inicializado com sucesso.")
        except Exception as e:
            logger.exception("N√£o foi poss√≠vel inicializar AzureChatOpenAI: %s", e)
            self.llm = None

        # Se LLM inicializou, cria toolkit e agent_executor
        if self.llm:
            toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)
            try:
                self.agent_executor = create_sql_agent(
                    llm=self.llm,
                    toolkit=toolkit,
                    verbose=True,
                    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                    memory=ConversationBufferWindowMemory(k=10)
                )
                logger.info("Agent executor criado com sucesso.")
            except Exception as e:
                logger.exception("Erro ao criar agent_executor: %s", e)
                self.agent_executor = None

            # Prompt e chain tamb√©m
            self.prompt = ChatPromptTemplate.from_template(
                """
                Voc√™ √© um especialista em an√°lise de dados.
                Dataset carregado com {rows} linhas e {cols} colunas.
                Colunas dispon√≠veis: {columns}.
                Pergunta do usu√°rio: {question}
                Responda de forma detalhada, trazendo poss√≠veis an√°lises, estat√≠sticas e insights.
                """
            )

            try:
                self.chain = LLMChain(llm=self.llm, prompt=self.prompt)
            except Exception as e:
                logger.exception("Erro ao criar LLMChain: %s", e)
                self.chain = None
        else:
            # Modo fallback (sem LLM) ‚Äî mant√©m os atributos definidos
            self.agent_executor = None
            self.chain = None
            self.prompt = ChatPromptTemplate.from_template(
                """
                Voc√™ √© um especialista em an√°lise de dados (modo offline).
                Dataset carregado com {rows} linhas e {cols} colunas.
                Colunas dispon√≠veis: {columns}.
                Pergunta do usu√°rio: {question}
                Responda de forma detalhada, trazendo poss√≠veis an√°lises, estat√≠sticas e insights.
                """
            )
            logger.warning("LLM n√£o inicializado. Agente pronto em modo offline.")
    
    
    def analyze_data(self, question: str) -> str:
        """Analisa dados baseado na pergunta"""
        if self.agent_executor:
            try:
                response = self.agent_executor.run(
                    f"{question}\nMem√≥ria atual: {self.memory.get_memory_summary()}"
                )
                return response
            except Exception as e:
                return f"Erro no agente: {str(e)}"
        else:
            return self._manual_analysis(question)
    
    def _manual_analysis(self, question: str) -> str:
        """An√°lise manual quando o agente n√£o est√° dispon√≠vel"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['b√°sica', 'resumo', 'overview', 'informa√ß√£o']):
            return self._get_basic_summary()
        elif any(word in question_lower for word in ['correla√ß√£o', 'rela√ß√£o', 'correlation']):
            return self._get_correlation_analysis()
        elif any(word in question_lower for word in ['outlier', 'anomalia', 'at√≠pico']):
            return self._get_outlier_analysis()
        elif any(word in question_lower for word in ['cluster', 'agrupamento', 'padr√£o']):
            return self._get_clustering_analysis()
        else:
            return "Pergunta n√£o reconhecida. Tente perguntas sobre informa√ß√µes b√°sicas, correla√ß√µes, outliers ou clustering."
    
    def _get_basic_summary(self) -> str:
        """Retorna resumo b√°sico dos dados"""
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        
        summary = f"""
        üìä **RESUMO DO DATASET**
        
        **Dimens√µes:** {self.df.shape[0]} linhas √ó {self.df.shape[1]} colunas
        
        **Tipos de Dados:**
        - Num√©ricas: {list(numeric_cols)} ({len(numeric_cols)} colunas)
        - Categ√≥ricas: {list(categorical_cols)} ({len(categorical_cols)} colunas)
        
        **Valores Ausentes:**
        {self.df.isnull().sum().to_string()}
        
        **Estat√≠sticas Descritivas (Num√©ricas):**
        {self.df[numeric_cols].describe().to_string()}
        """
        
        # Adicionar √† mem√≥ria
        self.memory.add_analysis("basic_summary", {
            "shape": self.df.shape,
            "numeric_cols": list(numeric_cols),
            "categorical_cols": list(categorical_cols)
        })
        
        return summary
    
    def _get_correlation_analysis(self) -> str:
        """An√°lise de correla√ß√£o"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        
        if numeric_df.empty:
            return "‚ùå N√£o h√° colunas num√©ricas para an√°lise de correla√ß√£o."
        
        corr_matrix = numeric_df.corr()
        
        # Encontrar correla√ß√µes fortes
        strong_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_value = corr_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    strong_corr.append((
                        corr_matrix.columns[i],
                        corr_matrix.columns[j],
                        corr_value
                    ))
        
        result = "üîó **AN√ÅLISE DE CORRELA√á√ÉO**\n\n"
        
        if strong_corr:
            result += "**Correla√ß√µes Fortes (|r| > 0.7):**\n"
            for var1, var2, corr in strong_corr:
                strength = "muito forte" if abs(corr) > 0.9 else "forte"
                direction = "positiva" if corr > 0 else "negativa"
                result += f"- {var1} ‚Üî {var2}: {corr:.3f} ({strength}, {direction})\n"
        else:
            result += "Nenhuma correla√ß√£o forte encontrada (|r| > 0.7)\n"
        
        # Adicionar √† mem√≥ria
        self.memory.add_analysis("correlation", strong_corr)
        
        return result
    
    def _get_outlier_analysis(self) -> str:
        """An√°lise de outliers"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        
        if numeric_df.empty:
            return "‚ùå N√£o h√° colunas num√©ricas para an√°lise de outliers."
        
        outliers_summary = {}
        
        for col in numeric_df.columns:
            Q1 = numeric_df[col].quantile(0.25)
            Q3 = numeric_df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]
            outliers_summary[col] = {
                'count': len(outliers),
                'percentage': (len(outliers) / len(numeric_df)) * 100,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound
            }
        
        result = "üö® **AN√ÅLISE DE OUTLIERS (M√©todo IQR)**\n\n"
        
        for col, info in outliers_summary.items():
            if info['count'] > 0:
                result += f"**{col}:**\n"
                result += f"  - Outliers detectados: {info['count']} ({info['percentage']:.2f}% dos dados)\n"
                result += f"  - Limites: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\n\n"
        
        # Adicionar √† mem√≥ria
        self.memory.add_analysis("outliers", outliers_summary)
        
        return result
    
    def _get_clustering_analysis(self) -> str:
        """An√°lise de clustering"""
        numeric_df = self.df.select_dtypes(include=[np.number]).dropna()
        
        if len(numeric_df.columns) < 2:
            return "‚ùå Insuficientes colunas num√©ricas para an√°lise de clustering."
        
        # Padronizar dados
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(numeric_df)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=3, random_state=42)
        clusters = kmeans.fit_predict(scaled_data)
        
        cluster_sizes = pd.Series(clusters).value_counts().sort_index()
        
        result = "üîç **AN√ÅLISE DE CLUSTERING (K-means, k=3)**\n\n"
        result += f"**Distribui√ß√£o dos Clusters:**\n"
        for cluster_id, size in cluster_sizes.items():
            percentage = (size / len(clusters)) * 100
            result += f"  - Cluster {cluster_id}: {size} pontos ({percentage:.1f}%)\n"
        
        result += f"\n**In√©rcia:** {kmeans.inertia_:.2f}"
        result += f"\n**Centros dos Clusters:** {len(kmeans.cluster_centers_)} centros identificados"
        
        # Adicionar √† mem√≥ria
        self.memory.add_analysis("clustering", {
            'cluster_sizes': cluster_sizes.to_dict(),
            'inertia': kmeans.inertia_
        })
        
        return result
    
    def get_conclusions(self) -> str:
        """Gera conclus√µes baseadas nas an√°lises realizadas"""
        if not self.memory.analyses:
            return "Nenhuma an√°lise foi realizada ainda."
        
        conclusions = []
        
        # An√°lise do dataset
        if self.memory.dataset_info:
            info = self.memory.dataset_info
            if info.get('missing_values'):
                missing_count = sum([v for v in info['missing_values'].values() if v > 0])
                if missing_count > 0:
                    conclusions.append(f"O dataset possui {missing_count} valores ausentes que podem precisar de tratamento.")
        
        # Conclus√µes sobre correla√ß√µes
        for analysis in self.memory.analyses:
            if analysis['type'] == 'correlation' and analysis['result']:
                conclusions.append("Foram identificadas correla√ß√µes fortes entre vari√°veis, indicando poss√≠veis rela√ß√µes lineares.")
        
        # Conclus√µes sobre outliers
        outlier_analyses = [a for a in self.memory.analyses if a['type'] == 'outliers']
        if outlier_analyses:
            latest_outliers = outlier_analyses[-1]['result']
            total_outliers = sum([info['count'] for info in latest_outliers.values()])
            if total_outliers > 0:
                conclusions.append(f"Foram detectados {total_outliers} outliers no dataset que podem afetar as an√°lises.")
        
        # Conclus√µes sobre clustering
        cluster_analyses = [a for a in self.memory.analyses if a['type'] == 'clustering']
        if cluster_analyses:
            conclusions.append("Os dados mostram padr√µes de agrupamento, sugerindo diferentes segmentos nos dados.")
        
        # Adicionar conclus√µes √† mem√≥ria
        final_conclusion = "\n".join([f"‚Ä¢ {c}" for c in conclusions])
        if final_conclusion:
            self.memory.add_conclusion(final_conclusion)
        
        return final_conclusion if conclusions else "Com base nas an√°lises realizadas, n√£o foram identificados padr√µes significativos que requerem aten√ß√£o especial."

def create_visualizations(df: pd.DataFrame, analysis_type: str):
    """Cria visualiza√ß√µes baseadas no tipo de an√°lise"""
    
    if analysis_type == "distribution":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            fig = go.Figure()
            
            for col in numeric_cols[:4]:  # M√°ximo 4 colunas
                fig.add_trace(go.Histogram(
                    x=df[col],
                    name=col,
                    opacity=0.7
                ))
            
            fig.update_layout(
                title="Distribui√ß√£o das Vari√°veis Num√©ricas",
                xaxis_title="Valor",
                yaxis_title="Frequ√™ncia",
                barmode='overlay'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "correlation":
        numeric_df = df.select_dtypes(include=[np.number])
        
        if not numeric_df.empty and len(numeric_df.columns) > 1:
            corr_matrix = numeric_df.corr()
            
            fig = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                title="Matrix de Correla√ß√£o",
                color_continuous_scale='RdBu_r'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "outliers":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            fig = go.Figure()
            
            for col in numeric_cols[:4]:  # M√°ximo 4 colunas
                fig.add_trace(go.Box(
                    y=df[col],
                    name=col
                ))
            
            fig.update_layout(
                title="Detec√ß√£o de Outliers (Box Plots)",
                yaxis_title="Valor"
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "scatter":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) >= 2:
            col1, col2 = numeric_cols[0], numeric_cols[1]
            
            fig = px.scatter(
                df,
                x=col1,
                y=col2,
                title=f"Gr√°fico de Dispers√£o: {col1} vs {col2}"
            )
            
            st.plotly_chart(fig, use_container_width=True)

def main():
    """Fun√ß√£o principal do aplicativo"""
    
    # T√≠tulo e descri√ß√£o
    st.title("üîç Especialista em An√°lise de Dados com IA")
    st.markdown("### Sistema inteligente para an√°lise explorat√≥ria de dados com agentes LangChain")
    
    

    # Sidebar para upload e configura√ß√µes
    with st.sidebar:
        st.header("üìÅ Upload de Dados")
        
        uploaded_file = st.file_uploader(
            "Fa√ßa upload do seu arquivo",
            type=['xls', 'xlsx', 'csv', 'txt'],
            help="Upload de um arquivo para an√°lise"
        )
        
        if uploaded_file is not None:
            try:
                # Carregar dados
                df = pd.read_csv(uploaded_file)
                st.success(f"Arquivo carregado: {uploaded_file.name}")
                st.info(f"Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
                
                # Armazenar no session state
                st.session_state['df'] = df
                st.session_state['uploaded'] = True
                
            except Exception as e:
                st.error(f"Erro ao carregar arquivo: {str(e)}")
                st.session_state['uploaded'] = False
        
        #Caixa de texto para perguntas
        st.header("‚ùì Diga sua pergunta")
        text_area = st.text_area(
            "Digite sua pergunta sobre os dados ap√≥s o upload",
            placeholder="Exemplo:\n- Quais s√£o as principais correla√ß√µes nos dados?",
            height=130,
            help="Seja espec√≠fico em sua pergunta para obter melhores respostas"
        )
        if st.button("üöÄ Enviar Pergunta"):
            if text_area.strip():
                with st.spinner("Processando..."):
                    try:
                        response = st.session_state.agent.analyze_data(text_area)
                        st.success("‚úÖ Resposta do Agente:")
                        st.write(response)
                    except Exception as e:
                        st.error(f"‚ùå Erro: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Digite uma pergunta antes de enviar.")    
    
    # √Årea principal
    if st.session_state.get('uploaded', False) and 'df' in st.session_state:
        df = st.session_state['df']
        
        # Inicializar agente
        if 'agent' not in st.session_state:
            db_path = "temp_data.db"
            st.session_state['agent'] = DataAnalysisAgent(df, db_path)
        
        agent = st.session_state['agent']
        
        # Tabs principais
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìä Vis√£o Geral", 
            "ü§ñ Chat com IA", 
            "üìà Visualiza√ß√µes", 
            "üí° Conclus√µes"
        ])
        
        with tab1:
            st.header("Vis√£o Geral dos Dados")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Informa√ß√µes B√°sicas")
                st.write(f"**Linhas:** {df.shape[0]}")
                st.write(f"**Colunas:** {df.shape[1]}")
                st.write(f"**Mem√≥ria:** {df.memory_usage().sum() / 1024**2:.2f} MB")
            
            with col2:
                st.subheader("Tipos de Dados")
                dtype_counts = df.dtypes.value_counts()
                st.write(dtype_counts)
            
            st.subheader("Pr√©via dos Dados")
            st.dataframe(df.head(10))
            
            st.subheader("Informa√ß√µes Detalhadas")
            st.text(df.info())
            
            st.subheader("Estat√≠sticas Descritivas")
            st.dataframe(df.describe())
        
        with tab2:
            st.header("üí¨ Chat com o Especialista em Dados")
            
            # Perguntas sugeridas
            st.subheader("Perguntas Sugeridas:")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("üìã Resumo b√°sico dos dados"):
                    with st.spinner("Analisando..."):
                        response = agent.analyze_data("Forne√ßa um resumo b√°sico dos dados")
                        st.write(response)
                
                if st.button("üîó An√°lise de correla√ß√µes"):
                    with st.spinner("Calculando correla√ß√µes..."):
                        response = agent.analyze_data("Analise as correla√ß√µes entre as vari√°veis")
                        st.write(response)
            
            with col2:
                if st.button("üö® Detectar outliers"):
                    with st.spinner("Detectando anomalias..."):
                        response = agent.analyze_data("Detecte outliers nos dados")
                        st.write(response)
                
                if st.button("üîç An√°lise de clustering"):
                    with st.spinner("Analisando padr√µes..."):
                        response = agent.analyze_data("Realize an√°lise de clustering")
                        st.write(response)
            
            st.divider()
            
            # Chat personalizado
            st.subheader("üí¨ Fa√ßa sua pergunta ao especialista:")
            
            # Container para o hist√≥rico de chat
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
            
            # Exibir hist√≥rico de chat
            if st.session_state.chat_history:
                st.subheader("üìã Hist√≥rico da Conversa:")
                for i, (q, a) in enumerate(st.session_state.chat_history):
                    with st.expander(f"Pergunta {i+1}: {q[:50]}..."):
                        st.write(f"**ü§î Pergunta:** {q}")
                        st.write(f"**ü§ñ Resposta:** {a}")
                
                # Bot√£o para limpar hist√≥rico
                if st.button("üóëÔ∏è Limpar Hist√≥rico"):
                    st.session_state.chat_history = []
                    st.rerun()
            
            st.divider()
            
            # √Årea de entrada de texto
            with st.form("chat_form"):
                question = st.text_area(
                    "Digite sua pergunta sobre os dados:",
                    placeholder="Exemplo:\n- Quais s√£o as principais correla√ß√µes nos dados?\n- Existem outliers que devo me preocupar?\n- Como est√£o distribu√≠das as vari√°veis?\n- Que padr√µes voc√™ identifica nos dados?",
                    height=100,
                    help="Seja espec√≠fico em sua pergunta para obter melhores respostas"
                )
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    submit_button = st.form_submit_button("üöÄ Enviar Pergunta", use_container_width=True)
                with col2:
                    clear_button = st.form_submit_button("üßπ Limpar", use_container_width=True)
            
            # Processamento da pergunta
            if submit_button and question.strip():
                with st.spinner("üîç Analisando seus dados e processando a pergunta..."):
                    try:
                        # Adicionar contexto sobre os dados √† pergunta
                        enhanced_question = f"""
                        Baseado no dataset carregado com as seguintes caracter√≠sticas:
                        - Formato: {df.shape[0]} linhas e {df.shape[1]} colunas
                        - Colunas num√©ricas: {list(df.select_dtypes(include=[np.number]).columns)}
                        - Colunas categ√≥ricas: {list(df.select_dtypes(include=['object']).columns)}
                        
                        Pergunta do usu√°rio: {question}
                        
                        Por favor, forne√ßa uma an√°lise detalhada e espec√≠fica baseada nos dados.
                        """
                        
                        response = agent.analyze_data(enhanced_question)
                        
                        # Adicionar ao hist√≥rico
                        st.session_state.chat_history.append((question, response))
                        
                        # Exibir resposta
                        st.success("‚úÖ An√°lise conclu√≠da!")
                        
                        # Container para a resposta mais vis√≠vel
                        with st.container():
                            st.markdown("### ü§ñ Resposta do Especialista:")
                            
                            # Criar tabs para diferentes visualiza√ß√µes da resposta
                            tab_resp, tab_viz = st.tabs(["üìù Resposta", "üìä Visualiza√ß√µes"])
                            
                            with tab_resp:
                                st.markdown(response)
                                
                                # Bot√µes de a√ß√£o
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    if st.button("üëç √ötil"):
                                        st.success("Obrigado pelo feedback!")
                                with col2:
                                    if st.button("üîÑ Reformular"):
                                        st.info("Tente fazer a pergunta de forma diferente")
                                with col3:
                                    if st.button("üíæ Salvar"):
                                        # Aqui voc√™ pode implementar salvamento
                                        st.info("Resposta salva no hist√≥rico!")
                            
                            with tab_viz:
                                # Sugerir visualiza√ß√µes baseadas na pergunta
                                question_lower = question.lower()
                                if any(word in question_lower for word in ['correla√ß√£o', 'rela√ß√£o', 'correlation']):
                                    st.info("üí° Visualiza√ß√£o sugerida: V√° para a aba 'Visualiza√ß√µes' e selecione 'Correla√ß√µes'")
                                elif any(word in question_lower for word in ['outlier', 'anomalia', 'at√≠pico']):
                                    st.info("üí° Visualiza√ß√£o sugerida: V√° para a aba 'Visualiza√ß√µes' e selecione 'Outliers'")
                                elif any(word in question_lower for word in ['distribui√ß√£o', 'histograma']):
                                    st.info("üí° Visualiza√ß√£o sugerida: V√° para a aba 'Visualiza√ß√µes' e selecione 'Distribui√ß√µes'")
                                else:
                                    st.info("üí° Explore a aba 'Visualiza√ß√µes' para gr√°ficos relacionados √† sua pergunta")
                    
                    except Exception as e:
                        st.error(f"‚ùå Erro ao processar a pergunta: {str(e)}")
                        st.info("üí° Tente reformular sua pergunta ou use uma das perguntas sugeridas")
            
            elif submit_button and not question.strip():
                st.warning("‚ö†Ô∏è Por favor, digite uma pergunta antes de enviar.")
            
            elif clear_button:
                st.info("‚úÖ Campo de pergunta limpo!")
            
            # Se√ß√£o de dicas
            with st.expander("üí° Dicas para fazer boas perguntas"):
                st.markdown("""
                **üéØ Para obter melhores respostas:**
                
                **‚úÖ Perguntas espec√≠ficas funcionam melhor:**
                - "Qual a correla√ß√£o entre idade e sal√°rio?"
                - "Quantos outliers existem na coluna de vendas?"
                - "Quais vari√°veis t√™m maior impacto no resultado?"
                
                **‚ùå Evite perguntas muito gen√©ricas:**
                - "Me fale sobre os dados"
                - "O que voc√™ acha?"
                - "An√°lise tudo"
                
                **üîç Tipos de an√°lise dispon√≠veis:**
                - **Descritiva:** estat√≠sticas, distribui√ß√µes, resumos
                - **Correla√ß√£o:** relacionamentos entre vari√°veis
                - **Outliers:** valores at√≠picos e anomalias
                - **Clustering:** padr√µes e agrupamentos
                - **Tend√™ncias:** an√°lise temporal e padr√µes
                
                **üí¨ Exemplos de perguntas por categoria:**
                
                **üìä An√°lise Descritiva:**
                - "Quais s√£o as estat√≠sticas b√°sicas de cada vari√°vel?"
                - "Como est√£o distribu√≠dos os dados?"
                - "H√° muitos valores ausentes?"
                
                **üîó An√°lise de Relacionamentos:**
                - "Existe correla√ß√£o entre X e Y?"
                - "Quais vari√°veis se relacionam mais fortemente?"
                - "Como X influencia Y?"
                
                **üö® Detec√ß√£o de Anomalias:**
                - "H√° outliers nos dados?"
                - "Quais valores s√£o considerados at√≠picos?"
                - "Os outliers afetam a an√°lise?"
                
                **üîç Identifica√ß√£o de Padr√µes:**
                - "Existem grupos naturais nos dados?"
                - "H√° padr√µes temporais?"
                - "Que segmentos posso identificar?"
                """)
            
            # Atalhos para perguntas comuns
            st.subheader("‚ö° An√°lises R√°pidas:")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üìà An√°lise Completa", help="An√°lise explorat√≥ria completa dos dados"):
                    quick_question = "Fa√ßa uma an√°lise explorat√≥ria completa dos dados, incluindo estat√≠sticas descritivas, correla√ß√µes, outliers e padr√µes identificados."
                    with st.spinner("Realizando an√°lise completa..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### ü§ñ An√°lise Completa:")
                        st.markdown(response)
            
            with col2:
                if st.button("üîó Correla√ß√µes", help="An√°lise de correla√ß√µes entre vari√°veis"):
                    quick_question = "Analise as correla√ß√µes entre todas as vari√°veis num√©ricas e identifique os relacionamentos mais significativos."
                    with st.spinner("Analisando correla√ß√µes..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### üîó An√°lise de Correla√ß√µes:")
                        st.markdown(response)
            
            with col3:
                if st.button("‚ö†Ô∏è Problemas", help="Identifica problemas nos dados"):
                    quick_question = "Identifique poss√≠veis problemas nos dados como outliers, valores ausentes, inconsist√™ncias e outros issues que precisam de aten√ß√£o."
                    with st.spinner("Identificando problemas..."):
                        response = agent.analyze_data(quick_question)
                        st.session_state.chat_history.append((quick_question, response))
                        st.markdown("### ‚ö†Ô∏è Problemas Identificados:")
                        st.markdown(response)
        
        with tab3:
            st.header("üìà Visualiza√ß√µes")
            
            viz_type = st.selectbox(
                "Selecione o tipo de visualiza√ß√£o:",
                ["Distribui√ß√µes", "Correla√ß√µes", "Outliers", "Dispers√£o"]
            )
            
            if st.button("Gerar Visualiza√ß√£o"):
                with st.spinner("Criando visualiza√ß√£o..."):
                    if viz_type == "Distribui√ß√µes":
                        create_visualizations(df, "distribution")
                    elif viz_type == "Correla√ß√µes":
                        create_visualizations(df, "correlation")
                    elif viz_type == "Outliers":
                        create_visualizations(df, "outliers")
                    elif viz_type == "Dispers√£o":
                        create_visualizations(df, "scatter")
        
        with tab4:
            st.header("üí° Conclus√µes e Insights")
            
            if st.button("üß† Gerar Conclus√µes"):
                with st.spinner("Analisando todos os dados e gerando insights..."):
                    conclusions = agent.get_conclusions()
                    
                    if conclusions:
                        st.success("Conclus√µes geradas com base nas an√°lises realizadas:")
                        st.write(conclusions)
                    else:
                        st.info("Realize algumas an√°lises primeiro para gerar conclus√µes.")
            
            # Mostrar mem√≥ria do agente
            st.subheader("üìö Mem√≥ria do Agente")
            if agent.memory.analyses:
                st.write(f"**An√°lises realizadas:** {len(agent.memory.analyses)}")
                st.write(f"**Conclus√µes armazenadas:** {len(agent.memory.conclusions)}")
                
                with st.expander("Ver detalhes da mem√≥ria"):
                    st.text(agent.memory.get_memory_summary())
            else:
                st.info("Nenhuma an√°lise realizada ainda. Use o chat para fazer perguntas sobre os dados.")
    
    else:
        # P√°gina inicial quando n√£o h√° dados carregados
        st.info("üëà Fa√ßa upload de um arquivo CSV na sidebar para come√ßar a an√°lise")
        
        # Tutorial de uso
        st.subheader("üöÄ Como usar este sistema:")
        
        st.markdown("""
        1. **Upload de Dados**: Carregue seu arquivo CSV usando a sidebar
        2. **Vis√£o Geral**: Explore informa√ß√µes b√°sicas sobre seus dados
        3. **Chat com IA**: Fa√ßa perguntas em linguagem natural sobre os dados
        4. **Visualiza√ß√µes**: Gere gr√°ficos autom√°ticos para diferentes tipos de an√°lise
        5. **Conclus√µes**: Obtenha insights inteligentes baseados em todas as an√°lises
        
        ### ü§ñ Capacidades do Agente:
        - An√°lise explorat√≥ria completa (EDA)
        - Detec√ß√£o de padr√µes e tend√™ncias
        - Identifica√ß√£o de outliers e anomalias
        - An√°lise de correla√ß√µes entre vari√°veis
        - Clustering e segmenta√ß√£o
        - Conclus√µes inteligentes com mem√≥ria persistente
        
        ### üìä Tipos de Perguntas que pode fazer:
        - "Quais s√£o os principais insights destes dados?"
        - "Existem correla√ß√µes fortes entre as vari√°veis?"
        - "Como est√£o distribu√≠dos os dados?"
        - "H√° outliers que devo me preocupar?"
        - "Quais padr√µes voc√™ encontrou?"
        """)
        
        # Exemplo de dataset
        st.subheader("üìã Dataset de Exemplo")
        st.markdown("Experimente com este dataset de exemplo:")
        
        if st.button("Gerar Dataset de Exemplo"):
            # Criar dataset de exemplo
            np.random.seed(42)
            n_samples = 1000
            
            example_data = {
                'idade': np.random.randint(18, 80, n_samples),
                'salario': np.random.exponential(50000, n_samples) + 30000,
                'experiencia': np.random.randint(0, 40, n_samples),
                'satisfacao': np.random.uniform(1, 11, n_samples),
                'departamento': np.random.choice(['TI', 'Vendas', 'Marketing', 'RH', 'Financeiro'], n_samples),
                'performance': np.random.normal(7, 2, n_samples)
            }
            
            # Adicionar algumas correla√ß√µes
            example_data['salario'] += example_data['experiencia'] * 1000
            example_data['satisfacao'] += (example_data['performance'] - 7) * 0.5
            
            example_df = pd.DataFrame(example_data)
            
            # Salvar arquivo tempor√°rio
            example_df.to_csv('exemplo_dataset.csv', index=False)
            
            st.success("Dataset de exemplo criado!")
            st.dataframe(example_df.head())
            
            # Carregar automaticamente
            st.session_state['df'] = example_df
            st.session_state['uploaded'] = True
            st.rerun()

if __name__ == "__main__":
    # Inicializar session state
    if 'uploaded' not in st.session_state:
        st.session_state['uploaded'] = False
    
    main()